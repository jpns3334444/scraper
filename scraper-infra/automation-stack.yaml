AWSTemplateFormatVersion: "2010-09-09"
Description: "Scraper Automation - Lambda Function and EventBridge"

Parameters:
  InfraStackName:
    Type: String
    Description: Name of the infrastructure stack to import from
    Default: "scraper-infra-stack"
  NotificationEnabled:
    Type: String
    Default: "true"
    AllowedValues: ["true", "false"]
    Description: Whether to enable email notifications

Resources:
  ScraperTriggerLambda:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: trigger-scraper
      Handler: index.lambda_handler
      Role: 
        Fn::ImportValue: !Sub "${InfraStackName}-LambdaExecutionRoleArn"
      Runtime: python3.11
      Timeout: 900
      Environment:
        Variables:
          SNS_TOPIC_ARN: 
            Fn::ImportValue: !Sub "${InfraStackName}-ScraperNotificationTopicArn"
          NOTIFICATION_ENABLED: !Ref NotificationEnabled
      Code:
        ZipFile: |
          import boto3
          import json
          import os
          import time
          from datetime import datetime

          def lambda_handler(event, context):
              ssm = boto3.client("ssm")
              sns = boto3.client("sns")
              ec2 = boto3.client("ec2")
              
              sns_topic_arn = os.environ.get("SNS_TOPIC_ARN")
              notification_enabled = os.environ.get("NOTIFICATION_ENABLED", "true") == "true"
              
              # Find EC2 instance by tag
              try:
                  response = ec2.describe_instances(
                      Filters=[
                          {'Name': 'tag:Name', 'Values': ['MarketScraper']},
                          {'Name': 'instance-state-name', 'Values': ['running']}
                      ]
                  )
                  
                  instances = []
                  for reservation in response['Reservations']:
                      instances.extend(reservation['Instances'])
                  
                  if not instances:
                      error_msg = "No running MarketScraper instances found"
                      print(error_msg)
                      
                      if notification_enabled and sns_topic_arn:
                          sns.publish(
                              TopicArn=sns_topic_arn,
                              Message=f"❌ Scraper job failed to start\\n\\nError: {error_msg}",
                              Subject="Scraper Job - Error"
                          )
                      
                      return {
                          "statusCode": 404,
                          "body": json.dumps({"error": error_msg})
                      }
                  
                  instance_id = instances[0]['InstanceId']
                  print(f"Found MarketScraper instance: {instance_id}")
                  
              except Exception as e:
                  error_msg = f"Error finding EC2 instance: {str(e)}"
                  print(error_msg)
                  
                  if notification_enabled and sns_topic_arn:
                      sns.publish(
                          TopicArn=sns_topic_arn,
                          Message=f"❌ Scraper job failed to start\\n\\nError: {error_msg}",
                          Subject="Scraper Job - Error"
                      )
                  
                  return {
                      "statusCode": 500,
                      "body": json.dumps({"error": error_msg})
                  }
              
              print(f"Starting scraper job for instance: {instance_id}")
              start_time = datetime.now()
              
              try:
                  response = ssm.send_command(
                      InstanceIds=[instance_id],
                      DocumentName="AWS-RunShellScript",
                      Parameters={
                          "commands": [
                              "export OUTPUT_BUCKET=lifull-scrape-tokyo && python3 /home/ubuntu/scrape.py >> /var/log/scraper/run.log 2>&1"
                          ],
                          "executionTimeout": ["3600"]
                      }
                  )
                  
                  command_id = response['Command']['CommandId']
                  print(f"SSM command sent: {command_id}")
                  
                  status = "InProgress"
                  while status == "InProgress":
                      time.sleep(30)
                      invocation = ssm.get_command_invocation(
                          CommandId=command_id,
                          InstanceId=instance_id
                      )
                      status = invocation['Status']
                      print(f"Command status: {status}")
                  
                  end_time = datetime.now()
                  duration = (end_time - start_time).total_seconds()
                  
                  if notification_enabled and sns_topic_arn:
                      if status == "Success":
                          message = f"✅ Scraper job completed successfully\n\nStart Time: {start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}\nEnd Time: {end_time.strftime('%Y-%m-%d %H:%M:%S UTC')}\nDuration: {duration:.1f} seconds\nCommand ID: {command_id}\nInstance ID: {instance_id}\n\nCheck S3 bucket for scraped data."
                          subject = "Scraper Job - Success"
                      else:
                          message = f"❌ Scraper job failed\n\nStart Time: {start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}\nEnd Time: {end_time.strftime('%Y-%m-%d %H:%M:%S UTC')}\nDuration: {duration:.1f} seconds\nStatus: {status}\nCommand ID: {command_id}\nInstance ID: {instance_id}\n\nError Output:\n{invocation.get('StandardErrorContent', 'No error details available')}"
                          subject = "Scraper Job - Failed"
                      
                      sns.publish(
                          TopicArn=sns_topic_arn,
                          Message=message,
                          Subject=subject
                      )
                  
                  return {
                      "statusCode": 200,
                      "body": json.dumps({
                          "command_id": command_id,
                          "status": status,
                          "duration": duration,
                          "instance_id": instance_id
                      })
                  }
                  
              except Exception as e:
                  error_msg = f"Lambda error: {str(e)}"
                  print(error_msg)
                  
                  if notification_enabled and sns_topic_arn:
                      sns.publish(
                          TopicArn=sns_topic_arn,
                          Message=f"❌ Scraper job failed to start\\n\\nError: {error_msg}",
                          Subject="Scraper Job - Error"
                      )
                  
                  return {
                      "statusCode": 500,
                      "body": json.dumps({"error": error_msg})
                  }

  ScraperLambdaEventRule:
    Type: AWS::Events::Rule
    Properties:
      Name: trigger-scraper-rule
      ScheduleExpression: "cron(0 17 * * ? *)"  # 2 AM JST = 17:00 UTC
      State: ENABLED
      Targets:
        - Arn: !GetAtt ScraperTriggerLambda.Arn
          Id: ScraperLambdaTarget

  AllowEventBridgeToInvokeLambda:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref ScraperTriggerLambda
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt ScraperLambdaEventRule.Arn

Outputs:
  ScraperLambdaArn:
    Description: "ARN of the scraper trigger Lambda function"
    Value: !GetAtt ScraperTriggerLambda.Arn
    Export:
      Name: !Sub "${AWS::StackName}-ScraperLambdaArn"